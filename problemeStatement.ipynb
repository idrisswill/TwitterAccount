{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Problem statement:**\n",
    "I need a way to more quickly understand what's happening in the forums and act on it.\n",
    "I want a faster way to summarize trends on forums posts, figure out what question are good for me to answer and alert my teammates if the community is reporting something en masse.\n",
    "\n",
    "\n",
    "this in actually four separate problems:\n",
    "\n",
    "* Summarization (level of activity, new/emerging topics that are newly popular)\n",
    "* Flag question I'm likely to know the answer to\n",
    "    * Identify possible answerers for a given question\n",
    "* alerts based on anomaly detection(lots of community discussion around a specific topic)\n",
    "* Remove any reply made by a user considered as a bot\n",
    "**Measuring success:**\n",
    "\n",
    "Summarization:\n",
    "\n",
    "* User feedback on bot output (online learning)\n",
    "* Unsupervised NLU\n",
    "    * Manual verification of topics (hand tagging of topics)\n",
    "    * Manual verification of keywords\n",
    "\n",
    "Flagging questions:\n",
    "\n",
    "* Accuracy of predicting question I replied to using my forum post history.\n",
    "\n",
    "Alerts:\n",
    "\n",
    "* Accuracy at identifying past event/bugs\n",
    "\n",
    "Bot detection:\n",
    "* Accuracy of predicting bot followers using features of follower user.\n",
    "\n",
    "**Possible approaches to summarization:**\n",
    "* **Level of activity**\n",
    "    * time series modeling of  difference of  posts over time\n",
    "    * X posts this week (+- from last week), most popular (upvote), most replied to\n",
    "\n",
    "\n",
    "* Keywords\n",
    "    * https://www.sciencedirect.com/science/article/abs/pii/S0020025519308588?via%3Dihub\n",
    "    * faster\n",
    "* Topics\n",
    "    * More flexible to differences in vocabulary\n",
    "* Hybrid approach\n",
    "    * keywords + embedding to group similar keywords\n",
    "* Clustering based on embeddings\n",
    "    * Do we want to train our own embeddings?\n",
    "    * Look into current approaches\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Comparing unsupervised text clustering/class. methods:\n",
    "\n",
    "Our goal: find un group forum post and similar topics.\n",
    "\n",
    "Challenge:\n",
    "* We don't have labels or tags\n",
    "* Topics/clusters will change over time\n",
    "* We don't know how many clusters/topics we have, and we expect that to change over time\n",
    "* We don't have a lot of forum posts per day (~ 10 tweets/per)\n",
    "\n",
    "solutions:\n",
    "* Run model weekly & apply daily (to address sparsity of data)\n",
    "* Use unsupervised methods\n",
    "* Run model continuously/batch run (this means training time/cost is more important to consider)\n",
    "\n",
    "Unsupervised text clustering:\n",
    "\n",
    "Words -> inputs:\n",
    "* Embeddings(might be a problem if we don't train new embeddings for each time we run the model)\n",
    "    * Fasttext can handle out of vocabulary words\n",
    "    * Subword embeddings\n",
    "    * Biggest factor, how long do they take to train?\n",
    "    * Universal Sentence Encoder Embeddings\n",
    "* Tf-idf\n",
    "* LDA\n",
    "* \"Take the term-frequency matrix, remove the \"expected\" frequency (by subtracting, or using the column marginal as a noise model)\" Twitter conseil -Leland Mcinnes\n",
    "* Embeddings weighted with tf-idf\n",
    "* Embedding -> PCA remove principal component -Arora (2018) 'A simple but tough to beat baseline for sentence embeddings'\n",
    "* PLSA (\"cheper\" version of LDA)\n",
    "\n",
    "Topic modeling:\n",
    "* LDA (Latent Dirichlet allocation)\n",
    "    * Too slow, not great for us\n",
    "    * hard to interpret\n",
    "\n",
    "Clustering (with embedding):\n",
    "* Hierarchical clustering\n",
    "* Brown clusters\n",
    "    * hierarchical\n",
    "    * work on the word level\n",
    "    * can be updated actively\n",
    "    * Would need to find python code\n",
    "* DBSCAN\n",
    "    * needs embeddings for input\n",
    "    * should reduce dimensionality\n",
    "    * note: clusters should be of similar densities\n",
    "    * HDBSCAN is hierarchical\n",
    "\n",
    "Keywords\n",
    "* Unsupervised keyword extraction (YAKE )\n",
    "\n",
    "whole pipeline:\n",
    "* https://topsbm.github.io/\n",
    "* https://github.com/bigartm/bigartm\n",
    "\n",
    "\n",
    "\n",
    "1. words to numbers\n",
    "    * tfidf\n",
    "    * LDA\n",
    "    * PLSA\n",
    "    * Embeddings\n",
    "        *fasttext\n",
    "        * USE embeddings\n",
    "        * Glove?\n",
    "        * word2vec\n",
    "2. Dimensionality reduction\n",
    "    * UMAP\n",
    "    * PCA\n",
    "3. Clustering\n",
    "    * DBSCAN\n",
    "    * HDBSCAN\n",
    "    * Spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}